<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Sequential Hypothesis Testing and Safe Anytime Inference – My sparse website</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">My sparse website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../applications.html"> 
<span class="menu-text">Applications</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#preface-to-this-project" id="toc-preface-to-this-project" class="nav-link active" data-scroll-target="#preface-to-this-project">Preface to This Project</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#power-calulation" id="toc-power-calulation" class="nav-link" data-scroll-target="#power-calulation">Power calulation</a>
  <ul class="collapse">
  <li><a href="#formally" id="toc-formally" class="nav-link" data-scroll-target="#formally">Formally</a></li>
  <li><a href="#peeking" id="toc-peeking" class="nav-link" data-scroll-target="#peeking">Peeking</a></li>
  </ul></li>
  <li><a href="#betting-for-hypothesis-testing." id="toc-betting-for-hypothesis-testing." class="nav-link" data-scroll-target="#betting-for-hypothesis-testing.">Betting for Hypothesis Testing.</a>
  <ul class="collapse">
  <li><a href="#sequential-probability-ratio-test-sprt" id="toc-sequential-probability-ratio-test-sprt" class="nav-link" data-scroll-target="#sequential-probability-ratio-test-sprt">sequential probability ratio test (SPRT)</a></li>
  <li><a href="#simulation" id="toc-simulation" class="nav-link" data-scroll-target="#simulation">Simulation</a></li>
  <li><a href="#msprt" id="toc-msprt" class="nav-link" data-scroll-target="#msprt">mSPRT</a></li>
  <li><a href="#a-small-point" id="toc-a-small-point" class="nav-link" data-scroll-target="#a-small-point">A Small Point</a></li>
  <li><a href="#looking-into-if-the-distribion-mispecified" id="toc-looking-into-if-the-distribion-mispecified" class="nav-link" data-scroll-target="#looking-into-if-the-distribion-mispecified">Looking into if the distribion mispecified</a></li>
  <li><a href="#msprt-aplications" id="toc-msprt-aplications" class="nav-link" data-scroll-target="#msprt-aplications">mSPRT aplications</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a>
  <ul class="collapse">
  <li><a href="#a-final-remark" id="toc-a-final-remark" class="nav-link" data-scroll-target="#a-final-remark">A Final Remark</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Sequential Hypothesis Testing and Safe Anytime Inference</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="preface-to-this-project" class="level1">
<h1>Preface to This Project</h1>
<p>This project was one of those rabbit-hole endeavors. I wanted to learn about A/B testing, which turned out to be a straightforward hypothesis test with some power calculations.</p>
<p>Interestingly, the calculations for power analysis were concepts I had already learned during my bachelor’s degree. So, I decided to explore some newer methods instead. That led me to sequential testing—a fascinating field. It’s this intriguing mix of betting strategies, martingales, and a lot of other fun concepts.</p>
<p>I’m mostly writing this project for myself, so I have something to work on and a way to document my learning process. But if someone happens to stumble across this, they should be aware that it can get a bit technical. I’ve included references to the math so I can easily find it again, and I’ve conducted a few small simulation studies. These simulations help me get a sense of the performance of the methods while also allowing me to bend the assumptions a little to see what happens.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>So in this project i am looking in to Wald’s Sequential Probability Ratio Test also called SPRT and some variants like mSPRT. The reason i want to learn this, is sequsial testing method. This is used to make live monotering of of Hyposis. The reason i want to learn this, that it eliminates the need for power calucluastions, insted the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> is chosen/specified, and the sampling proces gones on, until the hyposis can be confirmed or rejected. This is more inline with how i would want to conduct experimetns, their is some simularty to stocastic bandit, where agent tryes to optimize reward will they learn, for SPRT, the goal is to stop the experiment when a hypsis can be confirmed ore rejected.</p>
<p>The use cases for this live experiment the big usecase being A/B testing, but some mention trials aswell, I would think it would be hard to get aproved.</p>
<p>These test is based on significan and p-values. so the subject matter is hyposis testing. I will asume the reader knows what this is (I mostly write these small blok for my self). My best explanation of signifanc and <span class="math inline">\(\alpha\)</span> is that is conducted a 100 of experiment i would expted the correct hyposis to be confiremd arround <span class="math inline">\((1-\alpha)*100\)</span> times.</p>
<p>So why use these Sequential test rather than normal likelihod ratio test og confiens intervalls and the reason is peeking, wish we will get into later.</p>
</section>
<section id="power-calulation" class="level1">
<h1>Power calulation</h1>
<p>This project started with me looking into power calculations. In this section i go throug how to make the power caluculations and look into what happens if on peeks.</p>
<p>So the power calulation works by the user setting the minimum effect they would want the calculate, and tolarance for type 1 error <span class="math inline">\(\alpha\)</span> and tolerance for type 2 <span class="math inline">\(\beta\)</span>.</p>
<p>Let <span class="math inline">\(X=X_1,\dots,x_n\)</span> be the data depend if <span class="math inline">\(x_i\sim \mathbb{N}(\mu,\sigma^2)\)</span> ore if mean <span class="math inline">\(\bar{X}\sim \mathbb{N}(\mu,\sigma^2)\)</span>, the last come often from the law of large number. one can use this method I am not goin in to much in detail here, relly like this <a href="https://rugg2.github.io/AB%20testing%20-%20a%20simple%20explanation%20of%20what%20power%20analysis%20does.html">explation</a>. The pivot is showen in the calulaten’s.</p>
<section id="formally" class="level2">
<h2 class="anchored" data-anchor-id="formally">Formally</h2>
<p>Let <span class="math inline">\(H_0\)</span> be the null and let <span class="math inline">\(H_1\)</span> be other hyposis</p>
<p><span class="math inline">\(\alpha\)</span> is the proberbillaty of making a type one error meaning</p>
<p><span class="math inline">\(P(acepting\: H_1\: when\: H_0\: is\: true)\)</span></p>
<p><span class="math inline">\(\beta\)</span> is the probillaty of type 2 error</p>
<p><span class="math inline">\(P(acepting\: H_0\: when\: H_1\: is\: true)\)</span></p>
<p>If the distribtion is nice meaning law of large number insure it conveges to normal distribuion.</p>
<p><span class="math display">\[n\geq 2(\frac{\phi^{-1}(1-\alpha-\phi^{-1}(1-\beta)}{\Delta/\sigma})^2\]</span></p>
<p><span class="math inline">\(\phi^{-1}\)</span> is the inverse cumulative standard normal distribution,</p>
<p><span class="math inline">\(\Delta\)</span> is the abeslut differnece in effect betwwen the null <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span>.</p>
<p><span class="math inline">\(\sigma\)</span> is the variance.</p>
</section>
<section id="peeking" class="level2">
<h2 class="anchored" data-anchor-id="peeking">Peeking</h2>
<p>Peeking is when a one looks at the data as they come in, using standart hyposis test method, and make a conclusion if they dont see a effect. The problem is that it destrou the coverage gaurenty. So if one look at the data as they flow in and end the experiment and before if their is no significans.</p>
<p>This idear of if we have hundret experiement, in <span class="math inline">\((1-\alpha)\)</span> the right hypothesis identified is not valid.</p>
<p>Below i have made some small simulations to ilustrate the problem</p>
<p><span class="math inline">\(A=a_1,\dots,a_n\)</span> and <span class="math inline">\(B=b_1,\dots,b_n\)</span> let <span class="math inline">\(a_i\)</span> and <span class="math inline">\(b_i\)</span> iid and let <span class="math inline">\(a_i\sim\mathbb{N}(0,1)\)</span> and <span class="math inline">\(b_i\sim\mathbb{N}(0,1)\)</span>.</p>
<p>Since <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> has the same distribuion their is no effect. This is sometime calle a A/A test. Sometimes this is used to test method in a live environment. If a useres test method, they should make get type 1 error cover from this.</p>
<p>At each point the simulation will draw with no replacment from A ore B calulat the p values and see if the true mean is in the confiden intervall.</p>
<div id="d4a8d645" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">42</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span>  <span class="co"># Number of samples in A and B</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>num_simulations <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Number of simulations</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>true_mean <span class="op">=</span> <span class="dv">0</span>  <span class="co"># True mean to check against</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>variance<span class="op">=</span><span class="dv">1</span> <span class="co"># varince know</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>a<span class="op">=</span>np.random.normal(true_mean,variance,n) <span class="co"># draw</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>b<span class="op">=</span>np.random.normal(true_mean,variance,n) <span class="co"># draw</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_sigficanlevet(A:<span class="bu">list</span>,B:<span class="bu">list</span>,A_variance:<span class="bu">float</span><span class="op">=</span><span class="dv">1</span>,B_variance:<span class="bu">float</span><span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    mean_A<span class="op">=</span>np.mean(A)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    mean_B<span class="op">=</span>np.mean(B)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> (mean_A <span class="op">-</span> mean_B) <span class="op">/</span> np.sqrt(A_variance <span class="op">/</span> <span class="bu">len</span>(A) <span class="op">+</span> B_variance<span class="op">/</span> <span class="bu">len</span>(B))</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    p_value <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> norm.cdf(<span class="bu">abs</span>(Z)))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> p_value</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_significant_seq(A: <span class="bu">list</span>, B: <span class="bu">list</span>, A_variance: <span class="bu">float</span> <span class="op">=</span> <span class="dv">1</span>, B_variance: <span class="bu">float</span> <span class="op">=</span> <span class="dv">1</span>):</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize an empty list to store the significant values</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    sig_seq <span class="op">=</span> []</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create copies of A and B for sampling without replacement</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    A_copy <span class="op">=</span> np.copy(A)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    B_copy <span class="op">=</span> np.copy(B)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize vectors for the selected samples</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    A_vector <span class="op">=</span> []</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    B_vector <span class="op">=</span> []</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample the first element from A and B</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    A_vector.append(A_copy[<span class="dv">0</span>])</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    A_copy <span class="op">=</span> np.delete(A_copy, <span class="dv">0</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    B_vector.append(B_copy[<span class="dv">0</span>])</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    B_copy <span class="op">=</span> np.delete(B_copy, <span class="dv">0</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initial significance level calculation</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    sig_seq.append(get_sigficanlevet(A_vector, B_vector))  <span class="co"># Assuming this function exists</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run the loop until both lists are empty</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(A_copy) <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">or</span> <span class="bu">len</span>(B_copy) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Randomly choose whether to sample from A or B</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.random.rand() <span class="op">&gt;</span> <span class="fl">0.5</span> <span class="kw">and</span> <span class="bu">len</span>(A_copy) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>            A_vector.append(A_copy[<span class="dv">0</span>])  <span class="co"># Append the first element from A</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>            A_copy <span class="op">=</span> np.delete(A_copy, <span class="dv">0</span>)  <span class="co"># Remove the sampled element from A</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">len</span>(B_copy) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>            B_vector.append(B_copy[<span class="dv">0</span>])  <span class="co"># Append the first element from B</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>            B_copy <span class="op">=</span> np.delete(B_copy, <span class="dv">0</span>)  <span class="co"># Remove the sampled element from B</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate and store the significance level at this step</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>        sig_seq.append(get_sigficanlevet(A_vector, B_vector))  <span class="co"># Assuming this function exists</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sig_seq</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_significance_seq(sig_seq):</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the significance sequence</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    plt.plot(sig_seq, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, color<span class="op">=</span><span class="st">'b'</span>, label<span class="op">=</span><span class="st">'Significance Level'</span>)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add horizontal line at y=0.05 for the threshold</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    plt.axhline(y<span class="op">=</span><span class="fl">0.05</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, label<span class="op">=</span><span class="st">'Significance Threshold (0.05)'</span>)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add small green line segments for significance values below 0.05</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, value <span class="kw">in</span> <span class="bu">enumerate</span>(sig_seq):</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> value <span class="op">&lt;</span> <span class="fl">0.05</span>:</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>            plt.plot([i, i], [<span class="dv">0</span>, value], color<span class="op">=</span><span class="st">'green'</span>, lw<span class="op">=</span><span class="dv">2</span>)  <span class="co"># Line from 0 to the value</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set limits for the y-axis between 0 and 1</span></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>    plt.ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adding labels and title</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Sample Number'</span>)</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Significance Level'</span>)</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Significance Level Sequence with Threshold at 0.05'</span>)</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adding a legend</span></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>result<span class="op">=</span>get_significant_seq(a,b)</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>plot_significance_seq(result)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="sequential-hypothesis-testing and-safe-anytime-inference_files/figure-html/cell-2-output-1.png" width="812" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As can be see from the plot the p values goes up and down doing the experiment, So if one was to stop the experiement when the p value cross a threshold. The cover is not correct, this means in this case that tyoe 1 error alot higer than one exptes.</p>
<p>So let look at how the coverage is affected by the peaking belove i have made small simulation that corespond make the plot above a 1000 times and with a wish effect p value <span class="math inline">\(0.05\)</span>. If doing the experiment detects an effect out of <span class="math inline">\(0.05\)</span>, it will stop (this is called a decision rule). This setup enables the simulation of coverage during the experimental process.</p>
<div id="55706bed" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_sigficanlevet(A:<span class="bu">list</span>,B:<span class="bu">list</span>,A_variance:<span class="bu">float</span><span class="op">=</span><span class="dv">1</span>,B_variance:<span class="bu">float</span><span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    mean_A<span class="op">=</span>np.mean(A)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    mean_B<span class="op">=</span>np.mean(B)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> (mean_A <span class="op">-</span> mean_B) <span class="op">/</span> np.sqrt(A_variance <span class="op">/</span> <span class="bu">len</span>(A) <span class="op">+</span> B_variance<span class="op">/</span> <span class="bu">len</span>(B))</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    p_value <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> norm.cdf(<span class="bu">abs</span>(Z)))</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> p_value</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_significant_seq(A: <span class="bu">list</span>, B: <span class="bu">list</span>, A_variance: <span class="bu">float</span> <span class="op">=</span> <span class="dv">1</span>, B_variance: <span class="bu">float</span> <span class="op">=</span> <span class="dv">1</span>):</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize an empty list to store the significant values</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create copies of A and B for sampling without replacement</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    A_copy <span class="op">=</span> np.copy(A)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    B_copy <span class="op">=</span> np.copy(B)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize vectors for the selected samples</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    A_vector <span class="op">=</span> []</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    B_vector <span class="op">=</span> []</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample the first element from A and B</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    A_vector.append(A_copy[<span class="dv">0</span>])</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    A_copy <span class="op">=</span> np.delete(A_copy, <span class="dv">0</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    B_vector.append(B_copy[<span class="dv">0</span>])</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    B_copy <span class="op">=</span> np.delete(B_copy, <span class="dv">0</span>)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    sig_erro<span class="op">=</span><span class="dv">0</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run the loop until both lists are empty</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(A_copy) <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">or</span> <span class="bu">len</span>(B_copy) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Randomly choose whether to sample from A or B</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.random.rand() <span class="op">&gt;</span> <span class="fl">0.5</span> <span class="kw">and</span> <span class="bu">len</span>(A_copy) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>            A_vector.append(A_copy[<span class="dv">0</span>])  <span class="co"># Append the first element from A</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>            A_copy <span class="op">=</span> np.delete(A_copy, <span class="dv">0</span>)  <span class="co"># Remove the sampled element from A</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">len</span>(B_copy) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>            B_vector.append(B_copy[<span class="dv">0</span>])  <span class="co"># Append the first element from B</span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>            B_copy <span class="op">=</span> np.delete(B_copy, <span class="dv">0</span>)  <span class="co"># Remove the sampled element from B</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate and store the significance level at this step</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(get_sigficanlevet(A_vector, B_vector)<span class="op">&lt;</span><span class="fl">0.05</span>):</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>            sig_erro<span class="op">=</span><span class="dv">1</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span> </span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sig_erro</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span>  <span class="co"># Number of samples in A and B</span></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>num_simulations <span class="op">=</span> <span class="dv">1000</span>  <span class="co"># Number of simulations</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>true_mean <span class="op">=</span> <span class="dv">0</span>  <span class="co"># True mean to check against</span></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>variance<span class="op">=</span><span class="dv">1</span> <span class="co"># varince know</span></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>estimated<span class="op">=</span>[]</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,num_simulations):</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>    a<span class="op">=</span>np.random.normal(true_mean,variance,n) <span class="co"># draw</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>    b<span class="op">=</span>np.random.normal(true_mean,variance,n) <span class="co"># draw</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>    estimated.append(run_significant_seq(a,b))</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"cover"</span>)</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.mean(estimated))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>cover
0.4074074074074074</code></pre>
</div>
</div>
<p>For these settings, I usually obtain an estimate of around 0.4, which, to me, seems high. In practice, a person would likely not peek at the data every time a new point arrives. This is merely intended to illustrate the problem of peeking.</p>
<p>If peeking causes problems, the solution seems obvious: avoid peeking. However, in practice, people often do.</p>
<p>The literature on the method introduced below discusses designing systems to account for user behavior. This includes cases where users receive credit for findings, even when peeking leads to results that may not be valid.</p>
<p>The goal is to develop mathematical models that mitigate the problem of peeking. Another approach is preregistration. That said, there are many valid reasons to evaluate results as data comes in and to stop when a clear conclusion can be drawn.</p>
</section>
</section>
<section id="betting-for-hypothesis-testing." class="level1">
<h1>Betting for Hypothesis Testing.</h1>
<p>The main idea behind betting in hypothesis testing is to reframe the problem of hypothesis testing into a game.<br>
In this game, if the null hypothesis is true, there should be no strategy to consistently earn money. However, if one starts making money by betting against the null hypothesis, at some point it becomes highly unlikely that the null is true, allowing one to reject it.</p>
<p>Let us think about this.<br>
To give an example, imagine you are betting on the outcomes of two coin flips. You can bet on whether the coins match (both heads or both tails) or not. The coins may either be fair or have a matching bias, meaning both coins have a higher probability of landing on heads or tails.</p>
<p>If you guess correctly, you double your money; if you guess incorrectly, you lose your money. Note that there are only two hypotheses here. A rational player would not bet all their money but rather a fraction of it. A small note: the optimal fraction can be determined by optimizing log wealth.</p>
<p>Let <span class="math inline">\(H_0\)</span> represent the null hypothesis that there is no difference between the coins, meaning they are fair. For a fair game, <span class="math inline">\(P(x = \text{match}) = 0.5\)</span>, and there is no strategy to earn money. You could always bet “match,” always bet “no match,” or condition your bets on the previous outcome—it doesn’t matter. This also means there are no consequences to betting on <span class="math inline">\(H_1\)</span>.</p>
<p>Now, if the coins are biased, say <span class="math inline">\(P(x = \text{match}) = 0.6\)</span>, the optimal strategy is to always bet on “match”.</p>
<p>The above fair game is a sup <a href="https://en.wikipedia.org/wiki/Martingale_(probability_theory)">martingale meaning</a> meaning that the expected winnings at any point in time are equal to or less than what one has currently, and the value of the wealth process is always positive.</p>
<p>Let <span class="math inline">\(M_t\)</span> represent the wealth process in the game, i.e., the amount of money one has at time <span class="math inline">\(t\)</span>.</p>
<p><a href="https://thestatsmap.com/Ville's-inequality">Ville’s inequality</a> states that</p>
<p><span class="math display">\[\mathbb{P}\left( \exists t \geq 1 : M_t \geq x \right) \leq \frac{\mathbb{E}[M_1]}{x}\]</span></p>
<p>This means that there is a set probability that <span class="math inline">\(M_t\)</span> will cross <span class="math inline">\(x\)</span> over the entire duration of the process, assuming the game is fair.</p>
<p>Now, if the game is not fair, at some point we will win enough money to cross the threshold defined by Ville’s inequality. On the other hand, if the game is fair, with some probability (determined by <span class="math inline">\(\alpha\)</span>), <span class="math inline">\(M_t\)</span> will still cross the inequality.</p>
<p>This provides the correct control for the null hypothesis, but it holds over the entire process.</p>
<section id="sequential-probability-ratio-test-sprt" class="level2">
<h2 class="anchored" data-anchor-id="sequential-probability-ratio-test-sprt">sequential probability ratio test (SPRT)</h2>
<p>A little more formal explanation of the SPRT:<br>
Here, we are only looking at two hypotheses and their corresponding points:</p>
<ul>
<li><span class="math inline">\(H_0: \theta = \theta_0\)</span>, where <span class="math inline">\(p(x_i)\)</span> is the distribution under the null hypothesis.<br>
</li>
<li><span class="math inline">\(H_1: \theta = \theta_1\)</span>, where <span class="math inline">\(q(x_i)\)</span> is the distribution under the alternative hypothesis.</li>
</ul>
<p>We begin with a wealth of one.</p>
<p>Under the null hypothesis, the expectation of the likelihood ratio is given by:</p>
<p><span class="math display">\[  
\mathbb{E}\left( \frac{q(X_i)}{p(X_i)} \right) = \int \frac{p(x)}{q(x)} q(x) \, dx = \int p(x) \, dx = 1  
\]</span></p>
<p>The wealth can be written as:</p>
<p><span class="math display">\[  
M_t = \prod_{i=1}^{T} \frac{q(X_i)}{p(X_i)}  
\]</span></p>
<p>This is a submartingale, and by using Ville’s inequality, we obtain a probability guarantee for the entire process.</p>
<p>Under the alternative hypothesis, the inverse of the likelihood ratio will be a submartingale, leading to two thresholds: one for rejecting the null hypothesis <span class="math inline">\(H_0\)</span> and one for rejecting <span class="math inline">\(H_1\)</span>.</p>
<p>Notice how simple the theory is here.</p>
</section>
<section id="simulation" class="level2">
<h2 class="anchored" data-anchor-id="simulation">Simulation</h2>
<p>Below i have made small simulation of the the fair game desciped above and the SPRT. both coins af fair meaning their is <span class="math inline">\(P(X=head)0.5\)</span> for both <span class="math inline">\(\alpha = 0.05\)</span></p>
<div id="24f590fc" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Variables for the experiment</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>p_coin_1 <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>p_coin_2 <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of match and no match</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>p_match <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> p_coin_1) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> p_coin_2) <span class="op">+</span> p_coin_1 <span class="op">*</span> p_coin_2</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>p_no_match <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> p_match</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Hypotheses</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>match <span class="op">=</span> <span class="fl">0.5</span>  <span class="co"># Null hypothesis</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>alternative_hypothesis <span class="op">=</span> <span class="fl">0.7</span>  <span class="co"># Alternative hypothesis</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Tolerances</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span>  <span class="co"># Type I error</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="fl">0.20</span>  <span class="co"># Type II error</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Thresholds</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.log(beta <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha))</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.log((<span class="dv">1</span> <span class="op">-</span> beta) <span class="op">/</span> alpha)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Make button</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ber_llr(h_0, h_1, outcome):</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co">    Calculate the log-likelihood ratio for a Bernoulli outcome.</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co">        h_0: Null hypothesis probability</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co">        h_1: Alternative hypothesis probability</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="co">        outcome: Observed outcome (0 or 1)</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="co">        Log-likelihood ratio for the given outcome.</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.log((h_1<span class="op">**</span>outcome <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> h_1)<span class="op">**</span>(<span class="dv">1</span> <span class="op">-</span> outcome)) <span class="op">/</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>                  (h_0<span class="op">**</span>outcome <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> h_0)<span class="op">**</span>(<span class="dv">1</span> <span class="op">-</span> outcome)))</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sprt(p_match, h_0, h_1, a, b):</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="co">    Perform Sequential Probability Ratio Test (SPRT).</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="co">        p_match: Probability of a match</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a><span class="co">        h_0: Null hypothesis probability</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="co">        h_1: Alternative hypothesis probability</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="co">        a: Lower threshold (log-scale)</span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="co">        b: Upper threshold (log-scale)</span></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="co">        Dictionary with test results.</span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    Lambda <span class="op">=</span> <span class="dv">0</span>  <span class="co"># Cumulative log-likelihood ratio</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    draws <span class="op">=</span> []  <span class="co"># Store outcomes</span></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    log_likelihood_sum <span class="op">=</span> [<span class="dv">0</span>]  <span class="co"># Track likelihood values</span></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>    confirmed_hypothesis <span class="op">=</span> <span class="va">None</span>  <span class="co"># Store confirmed hypothesis</span></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> Lambda <span class="op">&gt;</span> a <span class="kw">and</span> Lambda <span class="op">&lt;</span> b:</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>        outcome <span class="op">=</span> np.random.binomial(<span class="dv">1</span>, p_match)</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>        draws.append(outcome)</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>        Lambda <span class="op">+=</span> ber_llr(h_0, h_1, outcome)</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>        log_likelihood_sum.append(Lambda)</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine the final hypothesis</span></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> Lambda <span class="op">&gt;=</span> b:</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>        confirmed_hypothesis <span class="op">=</span> <span class="st">"Alternative"</span></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> Lambda <span class="op">&lt;=</span> a:</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>        confirmed_hypothesis <span class="op">=</span> <span class="st">"Null"</span></span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>        <span class="st">"confirmed_hypothesis"</span>: confirmed_hypothesis,</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>        <span class="st">"log_likelihood_sum"</span>: log_likelihood_sum,</span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>        <span class="st">"draws"</span>: draws,</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>        <span class="st">"length"</span>: <span class="bu">len</span>(draws)</span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the SPRT</span></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> sprt(p_match, match, alternative_hypothesis, a, b)</span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_cover_sprt(p_match, h_0, h_1, a, b,N<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a>    cover<span class="op">=</span>[]</span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>    length<span class="op">=</span>[]</span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>        sim_ob<span class="op">=</span>sprt(p_match, h_0, h_1, a, b)</span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>        cover.append(sim_ob[<span class="st">"confirmed_hypothesis"</span>]<span class="op">==</span><span class="st">"Null"</span>)</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>        length.append(sim_ob[<span class="st">"length"</span>])</span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"cover"</span>:np.mean(cover),<span class="st">"mean length"</span>:np.mean(length)}</span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a>sim_result <span class="op">=</span> simulate_cover_sprt(p_match, match, alternative_hypothesis, a, b,<span class="dv">10000</span>)</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"cover"</span>)</span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sim_result[<span class="st">"cover"</span>])</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"mean run length"</span>)</span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sim_result[<span class="st">"mean length"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>cover
0.9537
mean run length
18.2276</code></pre>
</div>
</div>
<p>As can be see the cover i correct of the hyposis.</p>
</section>
<section id="msprt" class="level2">
<h2 class="anchored" data-anchor-id="msprt">mSPRT</h2>
<p>In practice, one rarely has a point hypothesis but rather a null and composite hypothesis.<br>
The question is often whether there is an effect or not.<br>
The composite hypothesis is a combination of multiple hypotheses.</p>
<p>mSPRT uses a mixture distribution for this:<br>
<span class="math display">\[
\Lambda(X_n) = \int_{\theta}\prod_{i=1}^{n}\frac{f_{\theta}(x_i)}{f_{\theta_0}(x_i)}h(\theta)d\theta
\]</span></p>
<p>The same stopping threshold is used for <span class="math inline">\(B\)</span>, meaning type 1 error control is the same since, under the null, the log-likelihood is a submartingale:<br>
<span class="math display">\[
\mathbb{E_{\theta_0}}\left(\frac{f_{\theta}(x)}{f_{\theta_0}(x)}h(\theta)\right) = \int f_{\theta}(x)d\theta = 1
\]</span></p>
<p>This is described as “hedging your bets.” The idea here is that you are betting on multiple hypotheses.</p>
<p>It becomes a little more complicated when considering the composite hypothesis, as there are multiple hypotheses, and only one can be true. It is not a submartingale unless one finds a way to adjust the expectation as the process progresses. I have not found such a method. This means the lower threshold for the sequence is not valid.</p>
<p>What one can do instead is to set a limit on the amount of data one wants to gather and set <span class="math inline">\(\beta\)</span> to zero. This means losing type 2 error control.</p>
<p>A second option is two experiment with adjusted <span class="math inline">\(\beta\)</span>, using distributions on both sides of the null.<br>
- If both are stopped by the <span class="math inline">\(B\)</span> criterion, which is related to <span class="math inline">\(\alpha\)</span>, this would suggest the null is true.<br>
- If one confirms the null and the other rejects it, this would suggest evidence against the null.</p>
<p>Thus, it is easier to simply negate the type 2 error. In practice, the user chooses an <span class="math inline">\(\alpha\)</span>, the tolerance for type 1 error they are willing to accept, and a maximum number of experiments they want to perform or can afford. Then the experiment runs, and if the process is not stopped, the conclusion is that there was no significance.</p>
<p>Below i made a small simulation of how one can do this.</p>
<div id="bb6a14cc" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># SPRT implementation</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> msprt(l_null, l_composite, N_stopping, alpha, draw_function):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    draws <span class="op">=</span> []</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    log_likelihood_ratios <span class="op">=</span> []</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> np.log(<span class="dv">1</span> <span class="op">/</span> alpha)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    log_likelihood_ratio <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    decision <span class="op">=</span> <span class="st">"Null"</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_stopping):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> draw_function()</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        draws.append(x)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        log_likelihood_ratio <span class="op">+=</span> np.log(l_composite(x) <span class="op">/</span> l_null(x))</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        log_likelihood_ratios.append(log_likelihood_ratio)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> log_likelihood_ratios[i] <span class="op">&gt;</span> b:</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>            decision <span class="op">=</span> <span class="st">"Alternative"</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"confirmed_hypothesis"</span>: decision,</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"log_likelihood_sum"</span>: log_likelihood_ratio,</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"draws"</span>: draws,</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"length"</span>: <span class="bu">len</span>(draws),</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation of coverage</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_cover_msprt(l_null, l_composite, N_stopping, alpha, draw_function, N_experiments):</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    cover <span class="op">=</span> []</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    length <span class="op">=</span> []</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_experiments):</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        sim_ob <span class="op">=</span> msprt(l_null, l_composite, N_stopping, alpha, draw_function)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>        cover.append(sim_ob[<span class="st">"confirmed_hypothesis"</span>] <span class="op">==</span> <span class="st">"Null"</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>        length.append(sim_ob[<span class="st">"length"</span>])</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"cover"</span>: np.mean(cover), <span class="st">"mean length"</span>: np.mean(length)}</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood functions</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_likelihood_null(x, mean_null, std_dev_null):</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> norm.pdf(x, loc<span class="op">=</span>mean_null, scale<span class="op">=</span>std_dev_null)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_likelihood_composit(x, mean_1, std_dev_1, phi_1, mean_2, std_dev_2):</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> phi_1 <span class="op">*</span> norm.pdf(x, loc<span class="op">=</span>mean_1, scale<span class="op">=</span>std_dev_1) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> phi_1) <span class="op">*</span> norm.pdf(x, loc<span class="op">=</span>mean_2, scale<span class="op">=</span>std_dev_2)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>mean_true <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>variance_true <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>std_dev_true <span class="op">=</span> variance_true <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation</span></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>sim_result <span class="op">=</span> simulate_cover_msprt(</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>    l_null<span class="op">=</span><span class="kw">lambda</span> x: get_likelihood_null(x, mean_null<span class="op">=</span><span class="dv">0</span>, std_dev_null<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>    l_composite<span class="op">=</span><span class="kw">lambda</span> x: get_likelihood_composit(x, mean_1<span class="op">=-</span><span class="dv">2</span>, std_dev_1<span class="op">=</span><span class="dv">1</span>, phi_1<span class="op">=</span><span class="fl">0.5</span>, mean_2<span class="op">=</span><span class="dv">2</span>, std_dev_2<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>    N_stopping<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.05</span>,</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>    draw_function<span class="op">=</span><span class="kw">lambda</span>: np.random.normal(mean_true, std_dev_true),</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    N_experiments<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Results</span></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"cover:"</span>, sim_result[<span class="st">"cover"</span>])</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"mean length:"</span>, sim_result[<span class="st">"mean length"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>cover: 0.978
mean length: 978.082</code></pre>
</div>
</div>
<p>as can be see the cover is good.</p>
<p>Ville’s inequality can also be used for anytime-valid p-values:<br>
<span class="math display">\[
p_n = \min \left[ 1, \min \left( \tilde{\Lambda}_t^{-1} : t \leq n \right) \right]
\]</span></p>
<p>If one thinks about the equation, it is quite simple. This involves moving a horizontal line down until it hits the highest point of the likelihood ratio trajectory and finding the corresponding <span class="math inline">\(\alpha\)</span>.</p>
<p>There are important things to notice here. This way of looking at p-values is very consistent, meaning that if we gather evidence against the null, no matter what data is later gathered, the p-values do not rise again.</p>
<p>This stands in contrast to “normal” p-values, which can be inconsistent over time periods.</p>
<p>A very nice propperty.</p>
</section>
<section id="a-small-point" class="level2">
<h2 class="anchored" data-anchor-id="a-small-point">A Small Point</h2>
<p>The submartingale property comes under a very specific distribution under the null.<br>
So, one is not only testing if <span class="math inline">\(\theta = \theta_0\)</span> but also making assumptions about the distribution.<br>
The Central Limit Theorem (CLT) is very powerful in the sense that, by taking the mean, many distributions will converge, providing some robustness to the CLT.</p>
<p>However, when looking at every single point and making assumptions about the distribution, that robustness is not present in the same way.<br>
One way to combat this is by making batches of data, but this takes away some of the idea of anytime-valid confidence intervals.</p>
<p>A second approach would be to determine the number of times one is allowed to peek and adjust the <span class="math inline">\(\alpha\)</span> based on this.<br>
These methods suffer from some of the same incentive structure errors as normal p-values. Over-peeking becomes a problem, and people not involved in the analysis cannot see if this has occurred.</p>
</section>
<section id="looking-into-if-the-distribion-mispecified" class="level2">
<h2 class="anchored" data-anchor-id="looking-into-if-the-distribion-mispecified">Looking into if the distribion mispecified</h2>
<p>Below here i have made simulation the true distribuion is a t distribuion mean zero with variance 3 scale 1. The null is normal distribuion with variance 3 and mean zero. The only difference is the and the sape of the distribuionsion. The hyposis test is if the mean is the same.</p>
<div id="b794044c" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm, t</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># SPRT implementation</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> msprt(l_null, l_composite, N_stopping, alpha, draw_function):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    draws <span class="op">=</span> []</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    log_likelihood_ratios <span class="op">=</span> []</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> np.log(<span class="dv">1</span> <span class="op">/</span> alpha)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    log_likelihood_ratio <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    decision <span class="op">=</span> <span class="st">"Null"</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_stopping):</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> draw_function()</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        draws.append(x)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        log_likelihood_ratio <span class="op">+=</span> np.log(l_composite(x) <span class="op">/</span> l_null(x))</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        log_likelihood_ratios.append(log_likelihood_ratio)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> log_likelihood_ratios[i] <span class="op">&gt;</span> b:</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>            decision <span class="op">=</span> <span class="st">"Alternative"</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"confirmed_hypothesis"</span>: decision,</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"log_likelihood_sum"</span>: log_likelihood_ratio,</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"draws"</span>: draws,</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"length"</span>: <span class="bu">len</span>(draws),</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation of coverage</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_cover_msprt(l_null, l_composite, N_stopping, alpha, draw_function, N_experiments):</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    cover <span class="op">=</span> []</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    length <span class="op">=</span> []</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_experiments):</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        sim_ob <span class="op">=</span> msprt(l_null, l_composite, N_stopping, alpha, draw_function)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        cover.append(sim_ob[<span class="st">"confirmed_hypothesis"</span>] <span class="op">==</span> <span class="st">"Null"</span>)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>        length.append(sim_ob[<span class="st">"length"</span>])</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"cover"</span>: np.mean(cover), <span class="st">"mean length"</span>: np.mean(length)}</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood functions</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_likelihood_null(x, mean_null, std_dev_null):</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> norm.pdf(x, loc<span class="op">=</span>mean_null, scale<span class="op">=</span>std_dev_null)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_likelihood_composit(x, mean_1, std_dev_1, phi_1, mean_2, std_dev_2):</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> phi_1 <span class="op">*</span> norm.pdf(x, loc<span class="op">=</span>mean_1, scale<span class="op">=</span>std_dev_1) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> phi_1) <span class="op">*</span> norm.pdf(x, loc<span class="op">=</span>mean_2, scale<span class="op">=</span>std_dev_2)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>mean_true <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>variance_true <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>std_dev_true <span class="op">=</span> variance_true <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation</span></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>sim_result <span class="op">=</span> simulate_cover_msprt(</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    l_null<span class="op">=</span><span class="kw">lambda</span> x: get_likelihood_null(x, mean_null<span class="op">=</span><span class="dv">0</span>, std_dev_null<span class="op">=</span>np.sqrt(<span class="dv">3</span>)),</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>    l_composite<span class="op">=</span><span class="kw">lambda</span> x: get_likelihood_composit(x, mean_1<span class="op">=-</span><span class="dv">5</span>, std_dev_1<span class="op">=</span>np.sqrt(<span class="dv">3</span>), phi_1<span class="op">=</span><span class="fl">0.5</span>, mean_2<span class="op">=</span><span class="dv">5</span>, std_dev_2<span class="op">=</span>np.sqrt(<span class="dv">3</span>)),</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>    N_stopping<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.05</span>,</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>    draw_function <span class="op">=</span> <span class="kw">lambda</span>: t.rvs(df<span class="op">=</span><span class="dv">3</span>, loc<span class="op">=</span>mean_true, scale<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>    N_experiments<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Results</span></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"cover:"</span>, sim_result[<span class="st">"cover"</span>])</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"mean length:"</span>, sim_result[<span class="st">"mean length"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\johan\AppData\Local\Temp\ipykernel_10876\857125392.py:14: RuntimeWarning:

invalid value encountered in scalar divide
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>cover: 0.969
mean length: 969.087</code></pre>
</div>
</div>
<p>As can be see in this case one actullay get good cover in this case. The simulated cover is close to the teoretical but if I make the null distribuion wide the cover is much lees acurate.</p>
<p>below I have made a small change to the true distribusion so now the scale parater is 2 meaning a vider shape of the t distribusion. So the mean is the same but variance is diffrent.</p>
<div id="fc140409" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm, t</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># SPRT implementation</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> msprt(l_null, l_composite, N_stopping, alpha, draw_function):</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    draws <span class="op">=</span> []</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    log_likelihood_ratios <span class="op">=</span> []</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> np.log(<span class="dv">1</span> <span class="op">/</span> alpha)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    log_likelihood_ratio <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    decision <span class="op">=</span> <span class="st">"Null"</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_stopping):</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> draw_function()</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        draws.append(x)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        log_likelihood_ratio <span class="op">+=</span> np.log(l_composite(x) <span class="op">/</span> l_null(x))</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        log_likelihood_ratios.append(log_likelihood_ratio)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> log_likelihood_ratios[i] <span class="op">&gt;</span> b:</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>            decision <span class="op">=</span> <span class="st">"Alternative"</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"confirmed_hypothesis"</span>: decision,</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"log_likelihood_sum"</span>: log_likelihood_ratio,</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"draws"</span>: draws,</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"length"</span>: <span class="bu">len</span>(draws),</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation of coverage</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_cover_msprt(l_null, l_composite, N_stopping, alpha, draw_function, N_experiments):</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    cover <span class="op">=</span> []</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    length <span class="op">=</span> []</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_experiments):</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>        sim_ob <span class="op">=</span> msprt(l_null, l_composite, N_stopping, alpha, draw_function)</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        cover.append(sim_ob[<span class="st">"confirmed_hypothesis"</span>] <span class="op">==</span> <span class="st">"Null"</span>)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>        length.append(sim_ob[<span class="st">"length"</span>])</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"cover"</span>: np.mean(cover), <span class="st">"mean length"</span>: np.mean(length)}</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood functions</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_likelihood_null(x, mean_null, std_dev_null):</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> norm.pdf(x, loc<span class="op">=</span>mean_null, scale<span class="op">=</span>std_dev_null)</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_likelihood_composit(x, mean_1, std_dev_1, phi_1, mean_2, std_dev_2):</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> phi_1 <span class="op">*</span> norm.pdf(x, loc<span class="op">=</span>mean_1, scale<span class="op">=</span>std_dev_1) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> phi_1) <span class="op">*</span> norm.pdf(x, loc<span class="op">=</span>mean_2, scale<span class="op">=</span>std_dev_2)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>mean_true <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>variance_true <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>std_dev_true <span class="op">=</span> variance_true <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation</span></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>sim_result <span class="op">=</span> simulate_cover_msprt(</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>    l_null<span class="op">=</span><span class="kw">lambda</span> x: get_likelihood_null(x, mean_null<span class="op">=</span><span class="dv">0</span>, std_dev_null<span class="op">=</span>np.sqrt(<span class="dv">3</span>)),</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>    l_composite<span class="op">=</span><span class="kw">lambda</span> x: get_likelihood_composit(x, mean_1<span class="op">=-</span><span class="dv">5</span>, std_dev_1<span class="op">=</span>np.sqrt(<span class="dv">3</span>), phi_1<span class="op">=</span><span class="fl">0.5</span>, mean_2<span class="op">=</span><span class="dv">5</span>, std_dev_2<span class="op">=</span>np.sqrt(<span class="dv">3</span>)),</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>    N_stopping<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.05</span>,</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>    draw_function <span class="op">=</span> <span class="kw">lambda</span>: t.rvs(df<span class="op">=</span><span class="dv">3</span>, loc<span class="op">=</span>mean_true, scale<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>    N_experiments<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Results</span></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"cover:"</span>, sim_result[<span class="st">"cover"</span>])</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"mean length:"</span>, sim_result[<span class="st">"mean length"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\johan\AppData\Local\Temp\ipykernel_10876\636247826.py:14: RuntimeWarning:

divide by zero encountered in scalar divide

C:\Users\johan\AppData\Local\Temp\ipykernel_10876\636247826.py:14: RuntimeWarning:

invalid value encountered in scalar divide
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>cover: 0.583
mean length: 589.663</code></pre>
</div>
</div>
<p>The coverage is now changed, as it should be. This is the point: the problem is that one is not only making assumptions about the values of the parameter but also about the distribution itself.</p>
<p>To sum up, in both these experiments, the model is mis-specified. However, if one is only interested in the mean, the coverage is quite good in one case and quite bad in the other.</p>
<p>Remember, these assumptions about the distribution need to be made before the experiment starts. Thus, one likely needs to gather some data to estimate the null distribution.</p>
<p>The same can be said about the distributions in the composite hypothesis. If I had to work with this in practice, I would conduct some simulation studies.</p>
<p>A good use case is convergence rates, which can be described by a Bernoulli distribution. This is particularly useful since the Bernoulli distribution only has one parameter, making it behave nicely in terms of distribution. By this, I mean that it should be less sensitive to being misspecified.</p>
</section>
<section id="msprt-aplications" class="level2">
<h2 class="anchored" data-anchor-id="msprt-aplications">mSPRT aplications</h2>
<p>Most of the implented aplications of mSPRT i found is based on (The article)[https://arxiv.org/pdf/1512.04922]</p>
<p>For the type II error control. It seam like that by running two test with leve <span class="math inline">\(\frac{\alpha}{2}\)</span> this come from <a href="https://www.sciencedirect.com/science/article/pii/S0022249621000109">A modified sequential probability ratio test</a>. I have desiced with my self i will look into this, if am gona use this in practis. So for now this is out of the scope of this asigment, but the idear is pretty brilliant. if one line the placement is null– alternetiv –True hyposis. if the true hyposis is very far of it should still work but the effect in the alternetiv hyposis will not be true, so the test becomes, more do one see a effect ore not posetiv effect and negativ effect.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Overall that a lot i like about the anytime valid p-values. I like the consitensy, i like dont have to make power calulation, i dont like that in mSPRT i am so depend on distribusion. I have to get the right distribtuion of null for it to be supmartingale. And for what the small example this the t distribuion, showed this can be problem.</p>
<p>Alot time CLT mean at for a lot of distribuions will convege to normal distribuion insuring some robustness. If one make batches of the data on could achieve some conveges to normal distribuion, but then one is actually not using the anytime propperty. Their is also other method one can look into their is overview over the different method <a href="https://engineering.atspotify.com/2023/03/">here</a>.</p>
<p>I would use it for convergens rates wich is bernuli distribusion, so the posbillatys to misspecifi the liklihood is limited, since it only dependt on one parameter.</p>
<section id="a-final-remark" class="level2">
<h2 class="anchored" data-anchor-id="a-final-remark">A Final Remark</h2>
<p>If I want <span class="math inline">\(\beta\)</span> control, I would run two SPRT tests with <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, and I would plot the distributions.<br>
Before starting, I would check if there is a region where the fraction <span class="math inline">\(\frac{p(x)}{q(x)}\)</span> varies significantly. I would also need to adjust <span class="math inline">\(\beta\)</span> accordingly.</p>
<p>However, if I only want <span class="math inline">\(\beta\)</span> control, I could run a single live experiment, set the maximum number of points I can afford to sample, and then stop either when the algorithm terminates or when I run out of budget.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>